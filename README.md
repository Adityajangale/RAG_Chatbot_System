# RAG Chatbot System (LangChain + FAISS + Ollama)

## ğŸ“Œ Overview
This project implements a Retrieval-Augmented Generation (RAG) chatbot that answers questions from PDF documents using semantic search and a local LLM.

The system:
- Loads PDF documents
- Splits text into chunks
- Generates embeddings
- Stores vectors using FAISS
- Retrieves relevant context
- Generates grounded answers using Ollama (phi3:mini)

---

## ğŸ§  Tech Stack
- Python
- Streamlit
- LangChain
- FAISS (Vector Database)
- Sentence Transformers
- Ollama (phi3:mini model)

---

## âš™ï¸ Architecture

User Query  
â†“  
FAISS Retrieval (Top-k)  
â†“  
Prompt Construction  
â†“  
LLM (phi3:mini)  
â†“  
Final Answer  

---

## ğŸš€ How to Run Locally

1. Clone the repository:


2. Install dependencies:


3. Install and run Ollama:


4. Run Streamlit:


---

## ğŸ“Š Features
- PDF-based knowledge retrieval
- FAISS vector indexing
- Controlled prompt to reduce hallucination
- Latency measurement
- Context-limited retrieval (k=1)
- Token limit for performance optimization

---

## ğŸ”® Future Improvements
- Hybrid search (BM25 + FAISS)
- Reranking with cross-encoder
- API-based LLM deployment
- Production-ready backend architecture

---

## ğŸ‘¤ Author
Aditya Jangale
